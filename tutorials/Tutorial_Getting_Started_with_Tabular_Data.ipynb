{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bukochgPFg7s"
   },
   "source": [
    "# Getting Started with tabular data!\n",
    "\n",
    "This notebook shows how to get started with Quantus using tabular data. For this purpose, we use the classic Titanic tabular dataset (Frank E. Harrell Jr., Thomas Cason):\n",
    "\n",
    "https://www.openml.org/d/40945\n",
    "\n",
    "The model in this notebook is taken from \"Getting started with Captum - Titanic Data Analysis\" provided by Captum:\n",
    "\n",
    "https://captum.ai/tutorials/Titanic_Basic_Interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Y7_mNf9Bic0"
   },
   "outputs": [],
   "source": [
    "!pip install quantus torch captum tensorflow-datasets\n",
    " \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RV7X-Ss9-16F"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.image import grayscale_to_rgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import quantus\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(27)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "np.random.seed(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGhP4bTuoWYF"
   },
   "source": [
    "## 1) Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqKzag4VFjHT"
   },
   "source": [
    "### 1.1 Load datasets\n",
    "\n",
    "We load the dataset using the tensorflow-datasets library. Alternatively, it can be downloaded directly from the OpenML website: https://www.openml.org/d/40945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TmsZxFhuc0mm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 10:37:01.758531: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "(ds, _), ds_info = tfds.load(\n",
    "    'titanic',\n",
    "    split=[\"train\", \"train[:1]\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "df = tfds.as_dataframe(ds, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['features/age', 'features/embarked', 'features/fare', 'features/parch', 'features/pclass', 'features/sex',\n",
    "       'features/sibsp', 'survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features/age</th>\n",
       "      <th>features/embarked</th>\n",
       "      <th>features/fare</th>\n",
       "      <th>features/parch</th>\n",
       "      <th>features/pclass</th>\n",
       "      <th>features/sex</th>\n",
       "      <th>features/sibsp</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.00000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.67660</td>\n",
       "      <td>1.495034</td>\n",
       "      <td>33.269279</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>1.294882</td>\n",
       "      <td>0.355997</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.381971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.86619</td>\n",
       "      <td>0.816130</td>\n",
       "      <td>51.747562</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>0.478997</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.486055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>512.329224</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features/age  features/embarked  features/fare  features/parch  \\\n",
       "count    1309.00000        1309.000000    1309.000000     1309.000000   \n",
       "mean       23.67660           1.495034      33.269279        0.385027   \n",
       "std        17.86619           0.816130      51.747562        0.865560   \n",
       "min        -1.00000           0.000000      -1.000000        0.000000   \n",
       "25%         7.00000           1.000000       7.895800        0.000000   \n",
       "50%        24.00000           2.000000      14.454200        0.000000   \n",
       "75%        35.00000           2.000000      31.275000        0.000000   \n",
       "max        80.00000           3.000000     512.329224        9.000000   \n",
       "\n",
       "       features/pclass  features/sex  features/sibsp     survived  \n",
       "count      1309.000000   1309.000000     1309.000000  1309.000000  \n",
       "mean          1.294882      0.355997        0.498854     0.381971  \n",
       "std           0.837836      0.478997        1.041658     0.486055  \n",
       "min           0.000000      0.000000        0.000000     0.000000  \n",
       "25%           1.000000      0.000000        0.000000     0.000000  \n",
       "50%           2.000000      0.000000        0.000000     0.000000  \n",
       "75%           2.000000      1.000000        1.000000     1.000000  \n",
       "max           2.000000      1.000000        8.000000     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "df_enc = pd.get_dummies(df, columns = ['features/embarked', 'features/pclass', 'features/sex']).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas dataframes to numpy arrays\n",
    "X = df_enc.drop(['survived'], axis=1).values\n",
    "Y = df_enc[\"survived\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test set\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmccxpA0n6MY"
   },
   "source": [
    "### 1.2 Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is based on \"Getting started with Captum - Titanic Data Analysis\" provided by Captum:\n",
    "\n",
    "https://captum.ai/tutorials/Titanic_Basic_Interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicSimpleNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(13, 12)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(12, 8)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.linear3 = nn.Linear(8, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lin1_out = self.linear1(x)\n",
    "        sigmoid_out1 = self.sigmoid1(lin1_out)\n",
    "        sigmoid_out2 = self.sigmoid2(self.linear2(sigmoid_out1))\n",
    "        return self.softmax(self.linear3(sigmoid_out2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 => Loss: 0.70\n",
      "Epoch 21/200 => Loss: 0.56\n",
      "Epoch 41/200 => Loss: 0.51\n",
      "Epoch 61/200 => Loss: 0.49\n",
      "Epoch 81/200 => Loss: 0.48\n",
      "Epoch 101/200 => Loss: 0.48\n",
      "Epoch 121/200 => Loss: 0.47\n",
      "Epoch 141/200 => Loss: 0.46\n",
      "Epoch 161/200 => Loss: 0.47\n",
      "Epoch 181/200 => Loss: 0.46\n"
     ]
    }
   ],
   "source": [
    "net = TitanicSimpleNNModel()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 200\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "input_tensor = torch.from_numpy(train_features).type(torch.FloatTensor)\n",
    "label_tensor = torch.from_numpy(train_labels)\n",
    "for epoch in range(num_epochs):    \n",
    "    output = net(input_tensor)\n",
    "    loss = criterion(output, label_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print ('Epoch {}/{} => Loss: {:.2f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8482532751091703\n"
     ]
    }
   ],
   "source": [
    "out_probs = net(input_tensor).detach().numpy()\n",
    "out_classes = np.argmax(out_probs, axis=1)\n",
    "print(\"Train Accuracy:\", sum(out_classes == train_labels) / len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7786259541984732\n"
     ]
    }
   ],
   "source": [
    "test_input_tensor = torch.from_numpy(test_features).type(torch.FloatTensor)\n",
    "out_probs = net(test_input_tensor).detach().numpy()\n",
    "out_classes = np.argmax(out_probs, axis=1)\n",
    "print(\"Test Accuracy:\", sum(out_classes == test_labels) / len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vY9mZQanaxr"
   },
   "source": [
    "### 1.3 Generate explanations\n",
    "\n",
    "In this example, we rely on the `captum` library. We use the Integrated Gradients method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor.requires_grad_()\n",
    "attr, delta = ig.attribute(test_input_tensor,target=1, return_convergence_delta=True)\n",
    "attr = attr.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuBkEBv3mihR"
   },
   "source": [
    "## 2) Quantative evaluation using Quantus\n",
    "\n",
    "We can evaluate our explanations on a variety of quantuative criteria but as a motivating example we test the ModelParameterRandomisation scores by Adebayo et al., 2018. This metric measures the distance between the original attribution and a newly computed attribution throughout the process of cascadingly/independently randomizing the model parameters of one layer at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aLjrKsT6mS9X"
   },
   "outputs": [],
   "source": [
    "# Define metric for evaluation.\n",
    "metric_init = quantus.ModelParameterRandomisation(\n",
    "    similarity_func=quantus.similarity_func.correlation_spearman,\n",
    "    return_sample_correlation=True,\n",
    "    return_aggregate=True,\n",
    "    aggregate_func=np.mean,\n",
    "    layer_order=\"independent\",\n",
    "    disable_warnings=True,\n",
    "    normalise=True,\n",
    "    abs=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iq7qqDfSmIdj"
   },
   "outputs": [],
   "source": [
    "# Return ModelParameterRandomisation scores for Integrated Gradients.\n",
    "scores_intgrad = metric_init(model=net, \n",
    "                            x_batch=test_features,\n",
    "                            y_batch=test_labels,\n",
    "                            a_batch=None,\n",
    "                            explain_func=quantus.explain,\n",
    "                            explain_func_kwargs={\"method\": \"IntegratedGradients\", \"reduce_axes\": ()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665171594087,
     "user": {
      "displayName": "Anna Hedström",
      "userId": "05540180366077551505"
     },
     "user_tz": -120
    },
    "id": "3kBrG51Lpuq9",
    "outputId": "5de8efa5-03ac-433d-ec7b-ead66740a545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelParameterRandomisation scores by Adebayo et al., 2018\n",
      "\n",
      " • Integrated Gradient =  [0.9538993763980916]\n"
     ]
    }
   ],
   "source": [
    "print(f\"ModelParameterRandomisation scores by Adebayo et al., 2018\\n\"       \n",
    "      f\"\\n • Integrated Gradient = \",scores_intgrad)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}