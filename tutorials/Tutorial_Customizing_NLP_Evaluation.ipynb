{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Customizing NLP evaluation with user-defined model, explanation functions, etc.\n",
    "\n",
    "In this tutorial we will:\n",
    "- Create our own text-classification model\n",
    "- Make it compatible with Quantus\n",
    "- Run evaluation with user-defined functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer, normalizers\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers.normalizers import NFD, Lowercase, StripAccents\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import string\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "VOCAB_SIZE = 15000\n",
    "EMBED_DIM = 128\n",
    "INTERMEDIATE_DIM = 512\n",
    "\n",
    "tf.config.list_physical_devices()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Datasets\n",
    "We use dataset for hate-speech detection. Warning, it can contain offensive language!\n",
    "More about dataset here [hate_speech_offensive](https://huggingface.co/datasets/hate_speech_offensive)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset hate_speech_offensive (/Users/artemsereda/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "658174c42663453da5e3c67ac1c5c83d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                                   tweet      label\n0      Cuffin these hoes man that's where you went ba...  offensive\n1      @AJ0427 @AshActually Hey, I don't always go th...  offensive\n2      RT @AthIeteChamp: Destroying a team that talke...  offensive\n3      Free bitch . We stay used yo hol yo each other...  offensive\n4                      RT @SteeloBrim: Captain Kirk hoe!  offensive\n...                                                  ...        ...\n24778          @alexiscarfield ya damn right nigglet! :D  offensive\n24779         RT @__PrettyTea: 30 bottles ! 30 bitches !  offensive\n24780               Fuuuuuck you you stupid fucking cunt  offensive\n24781  RT @studio6263: M&amp;S bids for most social C...    neither\n24782  If the servers for black ops 2 acts gay today ...  offensive\n\n[24783 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cuffin these hoes man that's where you went ba...</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@AJ0427 @AshActually Hey, I don't always go th...</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RT @AthIeteChamp: Destroying a team that talke...</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Free bitch . We stay used yo hol yo each other...</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @SteeloBrim: Captain Kirk hoe!</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24778</th>\n      <td>@alexiscarfield ya damn right nigglet! :D</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>24779</th>\n      <td>RT @__PrettyTea: 30 bottles ! 30 bitches !</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>24780</th>\n      <td>Fuuuuuck you you stupid fucking cunt</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>24781</th>\n      <td>RT @studio6263: M&amp;amp;S bids for most social C...</td>\n      <td>neither</td>\n    </tr>\n    <tr>\n      <th>24782</th>\n      <td>If the servers for black ops 2 acts gay today ...</td>\n      <td>offensive</td>\n    </tr>\n  </tbody>\n</table>\n<p>24783 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"hate_speech_offensive\")[\"train\"]\n",
    "X = ds[\"tweet\"]\n",
    "Y = ds[\"class\"]\n",
    "\n",
    "X, Y = shuffle(X, Y)\n",
    "\n",
    "label_mapping = {\n",
    "    2: \"neither\",\n",
    "    1: \"offensive\",\n",
    "    0: \"hate-speech\"\n",
    "}\n",
    "\n",
    "Y_text = [label_mapping[i] for i in Y]\n",
    "\n",
    "df = pd.DataFrame([X, Y_text], index=[\"tweet\", \"label\"]).T\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1. Data pre-processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Reference: https://www.kaggle.com/code/rushiwickramasooriya/nature\"\"\"\n",
    "    #Convert all text to lowercase words\n",
    "    text = str(text).lower()\n",
    "    #Remove numbers\n",
    "    text = re.sub('\\d+', '', text)\n",
    "    #Remove HTML tags\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    #Remove URLs\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    #Remove mentions\n",
    "    pattern = re.compile(r\"@\\w+\")\n",
    "    text = re.sub(pattern, '', text)\n",
    "    #Remove extra spaces\n",
    "    text = re.sub(' +', ' ', text).strip()\n",
    "    #Remove emoticons, symbols and pictographs, transport and map symbols, flags as well as emojis\n",
    "    text = re.sub(r\"[\"\n",
    "                  u\"\\U0001F600-\\U0001F64F\"\n",
    "                  u\"\\U0001F300-\\U0001F5FF\"\n",
    "                  u\"\\U0001F680-\\U0001F6FF\"\n",
    "                  u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                  u\"\\U00002702-\\U000027B0\"\n",
    "                  u\"\\U000024C2-\\U0001F251\"\n",
    "                  \"]+\", \"\", text)\n",
    "    #Remove punctuations\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.Tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))  # noqa\n",
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [NFD(), Lowercase(), StripAccents()]  # noqa\n",
    ")\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = WordPieceTrainer(\n",
    "    special_tokens=[\"[UNK]\", \"[PAD]\"],\n",
    "    vocab_size=VOCAB_SIZE,\n",
    ")  # noqa\n",
    "tokenizer.enable_truncation(max_length=MAX_SEQUENCE_LENGTH)\n",
    "tokenizer.enable_padding(pad_id=0, pad_token=\"[PAD]\")\n",
    "tokenizer.train_from_iterator(all_messages, trainer=trainer)\n",
    "#tokenizer.save(\"data/tokenizer.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Input pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Model\n",
    "\n",
    "We will create a simple model based on FNet architecture proposed in https://arxiv.org/abs/2105.03824\n",
    "Implementation is mostly taken from\n",
    "- https://github.com/keras-team/keras-nlp/blob/master/keras_nlp/layers/f_net_encoder.py\n",
    "- https://github.com/keras-team/keras-nlp/blob/master/keras_nlp/layers/token_and_position_embedding.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1 Build model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "WARNING:tensorflow:From /Users/artemsereda/miniconda3/envs/quantus/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 11:05:52.194018: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-23 11:05:52.194043: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_AXIS = -2\n",
    "\n",
    "\n",
    "def clone_initializer(initializer):\n",
    "    # If we get a string or dict, just return as we cannot and should not clone.\n",
    "    if not isinstance(initializer, tf.keras.initializers.Initializer):\n",
    "        return initializer\n",
    "    config = initializer.get_config()\n",
    "    return initializer.__class__.from_config(config)\n",
    "\n",
    "\n",
    "class FNetEncoder(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            intermediate_dim,\n",
    "            dropout=0,\n",
    "            activation=\"relu\",\n",
    "            layer_norm_epsilon=1e-5,\n",
    "            kernel_initializer=\"glorot_uniform\",\n",
    "            bias_initializer=\"zeros\",\n",
    "            name=None,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.dropout = dropout\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.layer_norm_epsilon = layer_norm_epsilon\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create layers based on input shape.\n",
    "        feature_size = input_shape[-1]\n",
    "\n",
    "        # Layer Norm layers.\n",
    "        self._mixing_layer_norm = tf.keras.layers.LayerNormalization(\n",
    "            epsilon=self.layer_norm_epsilon\n",
    "        )\n",
    "        self._output_layer_norm = tf.keras.layers.LayerNormalization(\n",
    "            epsilon=self.layer_norm_epsilon\n",
    "        )\n",
    "\n",
    "        # Feedforward layers.\n",
    "        self._intermediate_dense = tf.keras.layers.Dense(\n",
    "            self.intermediate_dim,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer=clone_initializer(self.kernel_initializer),\n",
    "            bias_initializer=clone_initializer(self.bias_initializer),\n",
    "        )\n",
    "        self._output_dense = tf.keras.layers.Dense(\n",
    "            feature_size,\n",
    "            kernel_initializer=clone_initializer(self.kernel_initializer),\n",
    "            bias_initializer=clone_initializer(self.bias_initializer),\n",
    "        )\n",
    "        self._output_dropout = tf.keras.layers.Dropout(rate=self.dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Forward pass of the FNetEncoder.\n",
    "\n",
    "        Args:\n",
    "            inputs: a Tensor. The input data to TransformerEncoder, should be\n",
    "                of shape [batch_size, sequence_length, feature_dim].\n",
    "\n",
    "        Returns:\n",
    "            A Tensor of the same shape as the `inputs`.\n",
    "        \"\"\"\n",
    "\n",
    "        def fourier_transform(input):\n",
    "            # Apply FFT on the input and take the real part.\n",
    "            # Before we apply fourier transform, let's convert the dtype of the\n",
    "            # input tensor to complex64.\n",
    "            input = tf.cast(input, tf.complex64)\n",
    "            mixing_output = tf.math.real(tf.signal.fft2d(input))\n",
    "            return mixing_output\n",
    "\n",
    "        def add_and_norm(input1, input2, norm_layer):\n",
    "            return norm_layer(input1 + input2)\n",
    "\n",
    "        def feed_forward(input):\n",
    "            x = self._intermediate_dense(input)\n",
    "            x = self._output_dense(x)\n",
    "            return self._output_dropout(x)\n",
    "\n",
    "        mixing_output = fourier_transform(inputs)\n",
    "\n",
    "        mixing_output = add_and_norm(\n",
    "            inputs, mixing_output, self._mixing_layer_norm\n",
    "        )\n",
    "\n",
    "        feed_forward_output = feed_forward(mixing_output)\n",
    "\n",
    "        x = add_and_norm(\n",
    "            mixing_output, feed_forward_output, self._output_layer_norm\n",
    "        )\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"intermediate_dim\": self.intermediate_dim,\n",
    "                \"dropout\": self.dropout,\n",
    "                \"activation\": tf.keras.activations.serialize(self.activation),\n",
    "                \"layer_norm_epsilon\": self.layer_norm_epsilon,\n",
    "                \"kernel_initializer\": tf.keras.initializers.serialize(\n",
    "                    self.kernel_initializer\n",
    "                ),\n",
    "                \"bias_initializer\": tf.keras.initializers.serialize(\n",
    "                    self.bias_initializer\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            sequence_length,\n",
    "            initializer=\"glorot_uniform\",\n",
    "            **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        if sequence_length is None:\n",
    "            raise ValueError(\n",
    "                \"`sequence_length` must be an Integer, received `None`.\"\n",
    "            )\n",
    "        self.sequence_length = int(sequence_length)\n",
    "        self.initializer = tf.keras.initializers.get(initializer)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"sequence_length\": self.sequence_length,\n",
    "                \"initializer\": tf.keras.initializers.serialize(self.initializer),\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_size = input_shape[-1]\n",
    "        self.position_embeddings = self.add_weight(\n",
    "            \"embeddings\",\n",
    "            shape=[self.sequence_length, feature_size],\n",
    "            initializer=self.initializer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if isinstance(inputs, tf.RaggedTensor):\n",
    "            bounding_shape = inputs.bounding_shape()\n",
    "            position_embeddings = self._trim_and_broadcast_position_embeddings(\n",
    "                bounding_shape,\n",
    "            )\n",
    "            # then apply row lengths to recreate the same ragged shape as inputs\n",
    "            return tf.RaggedTensor.from_tensor(\n",
    "                position_embeddings,\n",
    "                inputs.nested_row_lengths(),\n",
    "            )\n",
    "        else:\n",
    "            return self._trim_and_broadcast_position_embeddings(\n",
    "                tf.shape(inputs),\n",
    "            )\n",
    "\n",
    "    def _trim_and_broadcast_position_embeddings(self, shape):\n",
    "        input_length = shape[SEQUENCE_AXIS]\n",
    "        # trim to match the length of the input sequence, which might be less\n",
    "        # than the sequence_length of the layer.\n",
    "        position_embeddings = self.position_embeddings[:input_length, :]\n",
    "        # then broadcast to add the missing dimensions to match \"shape\"\n",
    "        return tf.broadcast_to(position_embeddings, shape)\n",
    "\n",
    "\n",
    "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocabulary_size,\n",
    "            sequence_length,\n",
    "            embedding_dim,\n",
    "            embeddings_initializer=\"glorot_uniform\",\n",
    "            mask_zero=False,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        if vocabulary_size is None:\n",
    "            raise ValueError(\n",
    "                \"`vocabulary_size` must be an Integer, received `None`.\"\n",
    "            )\n",
    "        if sequence_length is None:\n",
    "            raise ValueError(\n",
    "                \"`sequence_length` must be an Integer, received `None`.\"\n",
    "            )\n",
    "        if embedding_dim is None:\n",
    "            raise ValueError(\n",
    "                \"`embedding_dim` must be an Integer, received `None`.\"\n",
    "            )\n",
    "        self.vocabulary_size = int(vocabulary_size)\n",
    "        self.sequence_length = int(sequence_length)\n",
    "        self.embedding_dim = int(embedding_dim)\n",
    "        self.embeddings_initializer = tf.keras.initializers.get(\n",
    "            embeddings_initializer\n",
    "        )\n",
    "        self.token_embedding = tf.keras.layers.Embedding(\n",
    "            vocabulary_size,\n",
    "            embedding_dim,\n",
    "            embeddings_initializer=clone_initializer(\n",
    "                self.embeddings_initializer\n",
    "            ),\n",
    "            mask_zero=mask_zero,\n",
    "            name=\"token_embedding\"\n",
    "                 + str(tf.keras.backend.get_uid(\"token_embedding\")),\n",
    "        )\n",
    "        self.position_embedding = PositionEmbedding(\n",
    "            sequence_length=sequence_length,\n",
    "            initializer=clone_initializer(self.embeddings_initializer),\n",
    "            name=\"position_embedding\"\n",
    "                 + str(tf.keras.backend.get_uid(\"position_embedding\")),\n",
    "        )\n",
    "        self.supports_masking = self.token_embedding.supports_masking\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"vocabulary_size\": self.vocabulary_size,\n",
    "                \"sequence_length\": self.sequence_length,\n",
    "                \"embedding_dim\": self.embedding_dim,\n",
    "                \"embeddings_initializer\": tf.keras.initializers.serialize(\n",
    "                    self.embeddings_initializer\n",
    "                ),\n",
    "                \"mask_zero\": self.token_embedding.mask_zero,\n",
    "            },\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embedded_tokens = self.token_embedding(inputs)\n",
    "        embedded_positions = self.position_embedding(embedded_tokens)\n",
    "        outputs = embedded_tokens + embedded_positions\n",
    "        return outputs\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return self.token_embedding.compute_mask(inputs, mask=mask)\n",
    "\n",
    "\n",
    "input_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"input_ids\")\n",
    "x = TokenAndPositionEmbedding(\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    mask_zero=True,\n",
    ")(input_ids)\n",
    "\n",
    "x = FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "x = FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "x = FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(3, activation=\"softmax\", name=\"outputs\")(x)\n",
    "\n",
    "model = tf.keras.Model(input_ids, outputs, name=\"FNet\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2. Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3. Run example inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
