{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bukochgPFg7s"
   },
   "source": [
    "# Getting started\n",
    "\n",
    "This notebook shows how to get started with Quantus on tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MuA8v9jLp-pf"
   },
   "outputs": [],
   "source": [
    "# Imports general.\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tf_explain\n",
    "\n",
    "import quantus\n",
    "from quantus.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGhP4bTuoWYF"
   },
   "source": [
    "## 1. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqKzag4VFjHT"
   },
   "source": [
    "### 1.1 Load datasets\n",
    "\n",
    "We will then load a batch of input, output pairs that we generate explanations for, then to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TmsZxFhuc0mm"
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "ds_test = tfds.load(\n",
    "    'imagenet_v2',\n",
    "    split=['test'],\n",
    "    as_supervised=True,\n",
    "    batch_size=8,\n",
    "    try_gcs=True\n",
    ")\n",
    "ds_test = ds_test[0]\n",
    "ds_test = ds_test.map(lambda x,y: (tf.image.resize(x, (224, 224)), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_batch, y_batch = ds_test.take(1).as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1640102275943,
     "user": {
      "displayName": "Anna Hedström",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhbfsluHeZ1mzN6Bsf-1zU62lYHcz183jYjeS63=s64",
      "userId": "05540180366077551505"
     },
     "user_tz": -60
    },
    "id": "aAR67-cnOS67",
    "outputId": "694e08b4-89fd-4be9-d19a-161e9d41dcd5"
   },
   "outputs": [],
   "source": [
    "# Plot some inputs!\n",
    "i = 0\n",
    "nr_images = 5\n",
    "fig, axes = plt.subplots(nrows=1, ncols=nr_images, figsize=(nr_images*3, int(nr_images*2/3)))\n",
    "for x_batch, y_batch in ds_train.take(nr_images):\n",
    "    axes[i].imshow((np.reshape(x_batch.numpy(), (28, 28)) * 255).astype(np.uint8), vmin=0.0, vmax=1.0, cmap=\"gray\")\n",
    "    axes[i].title.set_text(f\"MNIST class - {y_batch}\")\n",
    "    axes[i].axis(\"off\")\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVpqMEDaLWyN"
   },
   "outputs": [],
   "source": [
    "# Build a training pipeline\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.expand_dims(tf.cast(image, tf.float32), axis = 3) / 255., label\n",
    "\n",
    "def to_rgb(image, label):\n",
    "    return grayscale_to_rgb(image), label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_l5GryjLWyU"
   },
   "outputs": [],
   "source": [
    "# Build an evaluation pipeline\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMnacP2QLWya",
    "outputId": "f6597a04-f688-4ed3-950f-d6c0daaecc61"
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(iter(ds_test))\n",
    "x_batch = x_batch.numpy() [:,:,:,0]\n",
    "y_batch = y_batch.numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmccxpA0n6MY"
   },
   "source": [
    "### 1.2 Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1640102275944,
     "user": {
      "displayName": "Anna Hedström",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhbfsluHeZ1mzN6Bsf-1zU62lYHcz183jYjeS63=s64",
      "userId": "05540180366077551505"
     },
     "user_tz": -60
    },
    "id": "CUghaOhXddLU",
    "outputId": "cb625cea-1bc4-477e-a549-4bd1e1a8e158"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")\n",
    "\n",
    "print(f\"\\n Model architecture: {model.summary()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vY9mZQanaxr"
   },
   "source": [
    "### 1.3 Generate explanations\n",
    "\n",
    "There exist multiple ways to generate explanations for neural network models e.g., using `captum` or `innvestigate` libraries. In this example, we rely on the `quantus.explain` functionality (a simple wrapper around `captum`) however use whatever approach or library you'd like to create your explanations.\n",
    "\n",
    "**Requirements.**\n",
    "\n",
    "* **Data type.** Similar to the x-y pairs, the attributions should also be of type `np.ndarray`\n",
    "* **Shape.** Sharing all the same dimensions as the input (expect for nr_channels which for explanations is equal to 1). For example, if x_batch is of size (128, 3, 224, 224) then the attributions should be of size (128, 1, 224, 224)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNxAtc2Co1pL"
   },
   "outputs": [],
   "source": [
    "# Generate Integrated Gradients attributions of the first batch of the test set.\n",
    "a_batch_intgrad = (\n",
    "            np.array(\n",
    "                list(\n",
    "                    map(\n",
    "                        lambda x, y: tf_explain.core.integrated_gradients.IntegratedGradients().explain(\n",
    "                            ([x], None), model, y, n_steps=10\n",
    "                        ),\n",
    "                        x_batch,\n",
    "                        y_batch,\n",
    "                    )\n",
    "                ),\n",
    "                dtype=float,\n",
    "            )\n",
    "            / 255\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRDwzUUp8bR2"
   },
   "source": [
    "Visualise attributions given model and pairs of input-output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "executionInfo": {
     "elapsed": 3146,
     "status": "ok",
     "timestamp": 1640102281314,
     "user": {
      "displayName": "Anna Hedström",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhbfsluHeZ1mzN6Bsf-1zU62lYHcz183jYjeS63=s64",
      "userId": "05540180366077551505"
     },
     "user_tz": -60
    },
    "id": "82WWNmyoilXo",
    "outputId": "46910bcf-1acd-46a0-f479-8512f967143c"
   },
   "outputs": [],
   "source": [
    "# Plot explanations!\n",
    "nr_images = 3\n",
    "fig, axes = plt.subplots(nrows=nr_images, ncols=2, figsize=(nr_images*2.5, int(nr_images*3)))\n",
    "for i in range(nr_images):\n",
    "    axes[i, 0].imshow((np.reshape(x_batch[i], (28, 28)) * 255).astype(np.uint8), vmin=0.0, vmax=1.0, cmap=\"gray\")\n",
    "    axes[i, 0].title.set_text(f\"MNIST digit {y_batch[i].item()}\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "    a = axes[i, 1].imshow(a_batch_intgrad[i], cmap=\"seismic\")\n",
    "    axes[i, 1].title.set_text(f\"Integrated Gradients\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuBkEBv3mihR"
   },
   "source": [
    "## 2. Quantative evaluation using Quantus\n",
    "\n",
    "We can evaluate our explanations on a variety of quantuative criteria but as a motivating example we test the Max-Sensitivity (Yeh at el., 2019) of the explanations. This metric tests how the explanations maximally change while subject to slight perturbations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLjrKsT6mS9X"
   },
   "outputs": [],
   "source": [
    "# Define metric for evaluation.\n",
    "metric_init = quantus.MaxSensitivity(nr_samples=10,\n",
    "    lower_bound=0.1,\n",
    "    norm_numerator=quantus.fro_norm,\n",
    "    norm_denominator=quantus.fro_norm,\n",
    "    perturb_func=quantus.uniform_noise,\n",
    "    similarity_func=quantus.difference,\n",
    "    disable_warnings=True,\n",
    "    normalise=True,\n",
    "    abs=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iq7qqDfSmIdj"
   },
   "outputs": [],
   "source": [
    "# Return Max-Sensitivity scores in an one-liner - by calling the metric instance.\n",
    "scores_intgrad_maxs = metric_init(model=model, \n",
    "                                  x_batch=x_batch,\n",
    "                                  y_batch=y_batch,\n",
    "                                  a_batch=a_batch_intgrad,\n",
    "                                  explain_func=quantus.explain,\n",
    "                                  explain_func_kwargs={\"method\": \"IntegratedGradients\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGYHGu1Esya7",
    "outputId": "14a1f886-81a2-471f-b3c8-995cbe33a133"
   },
   "outputs": [],
   "source": [
    "metrics = {\"max-Sensitivity\": quantus.MaxSensitivity(**params_eval_maxs)}\n",
    "\n",
    "xai_methods = {\"IntegratedGradients\": a_batch_intgrad}\n",
    "\n",
    "results = quantus.evaluate(metrics=metrics,\n",
    "                           xai_methods=xai_methods,\n",
    "                           model=model,\n",
    "                           x_batch=x_batch,\n",
    "                           y_batch=y_batch,\n",
    "                           agg_func=np.mean,\n",
    "                           explain_func=quantus.explain,\n",
    "                           explain_func_kwargs={\"method\": \"IntegratedGradients\"})\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzT_5l7wLWyk"
   },
   "outputs": [],
   "source": [
    "# Calculate Selectivity (Montavon et al., 2018)\n",
    "metric_init_select = quantus.Selectivity(perturb_func=quantus.baseline_replacement_by_patch,\n",
    "    disable_warnings=True,\n",
    "    normalise=True,\n",
    "    abs=True,\n",
    "    perturb_baseline=\"uniform\",\n",
    "    patch_size=4,\n",
    " )\n",
    "\n",
    "# Return Selectivity scores in an one-liner - by calling the metric instance.\n",
    "scores_intgrad_maxs = metric_init_select(model=model, \n",
    "                                  x_batch=x_batch,\n",
    "                                  y_batch=y_batch,\n",
    "                                  a_batch=a_batch_intgrad,\n",
    "                                  explain_func=quantus.explain,\n",
    "                                  explain_func_kwargs={\"method\": \"IntegratedGradients\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9DkYz4BuySK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
