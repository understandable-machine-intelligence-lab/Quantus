{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### In this notebook, we demonstrate how robustness evaluation of explanations for text classification models could look like"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quantus.nlp as qn\n",
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "import logging\n",
    "from typing import NamedTuple, Any\n",
    "from transformers import AutoTokenizer, TFDistilBertForSequenceClassification\n",
    "from IPython.display import HTML\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "logging.getLogger('absl').setLevel(logging.WARNING)\n",
    "tf.config.list_physical_devices()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load pre-trained model and tokenizer from [huggingface](https://huggingface.co/models) hub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(MODEL_NAME)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load test split of [GLUE/SST2](https://huggingface.co/datasets/sst2) dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "CLASS_NAMES = ['negative', 'positive']\n",
    "\n",
    "\n",
    "def decode_labels(y_batch):\n",
    "    return [CLASS_NAMES[i] for i in y_batch]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n",
      "WARNING:datasets.builder:Found cached dataset sst2 (/Users/artemsereda/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0728b5d6ae604a3e8fc48f691608e8f8"
      },
      "application/json": {
       "n": 0,
       "total": 3,
       "elapsed": 0.019500017166137695,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "dataset = load_dataset(\"sst2\")['test']\n",
    "x_batch = dataset['sentence'][:BATCH_SIZE]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Run an example inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   0         1\n0             uneasy mishmash of styles and genres .  negative\n1  this film 's relationship to actual tension is...  negative\n2  by the end of no such thing the audience , lik...  positive\n3  director rob marshall went out gunning to make...  positive\n4  lathan and diggs have considerable personal ch...  positive\n5  a well-made and often lovely depiction of the ...  positive\n6  none of this violates the letter of behan 's b...  negative\n7  although it bangs a very cliched drum at times...  positive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>uneasy mishmash of styles and genres .</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>this film 's relationship to actual tension is...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>by the end of no such thing the audience , lik...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>director rob marshall went out gunning to make...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lathan and diggs have considerable personal ch...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>a well-made and often lovely depiction of the ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>none of this violates the letter of behan 's b...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>although it bangs a very cliched drum at times...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(x_batch, padding='longest', return_tensors='tf')\n",
    "logits = model(**tokens).logits\n",
    "y_batch = tf.argmax(tf.nn.softmax(logits), axis=1).numpy()\n",
    "\n",
    "pd.DataFrame([x_batch, decode_labels(y_batch)]).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Let's also create a function to visualize our explanations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def _create_div(explanation: qn.TokenSalience, predicted_label):\n",
    "    div = (\n",
    "        \"\"\"\n",
    "        <div class=\"container\">\n",
    "            <p>\n",
    "                Predicted: {{predicted_label}} <br>\n",
    "                {{saliency_map}}\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    TOKEN_SPAN = (\n",
    "        \"\"\"\n",
    "        <span class=\"highlight-container\" style=\"background:{{color}};\">\n",
    "            <span class=\"highlight\"> {{token}} </span>\n",
    "        </span>\n",
    "        \"\"\"\n",
    "    )\n",
    "    tokens = explanation.tokens\n",
    "    grads = explanation.salience\n",
    "    body = \"\"\n",
    "    max_grad = np.max(grads)\n",
    "\n",
    "    for t, g in zip(tokens, grads):\n",
    "        green = 255.0 - 255.0 * (g / max_grad)\n",
    "        blue = 255.0 - 255.0 * (g / max_grad)\n",
    "        token_span = TOKEN_SPAN.replace(\n",
    "            \"{{color}}\", f\"rgb(255,{green},{blue})\"\n",
    "        ).replace(\"{{token}}\", t)\n",
    "        body += token_span + \" \"\n",
    "\n",
    "    return div.replace(\"{{predicted_label}}\", predicted_label).replace(\n",
    "        \"{{saliency_map}}\", body\n",
    "    )\n",
    "\n",
    "\n",
    "def create_textual_heatmap(explanations, predicted_labels):\n",
    "    style = (\n",
    "        \"\"\"\n",
    "        <style>\n",
    "\n",
    "            .container {\n",
    "                line-height: 1.4;\n",
    "                text-align: center;\n",
    "                margin: 10px 10px 10px 10px;\n",
    "                color: black;\n",
    "                background: white;\n",
    "            }\n",
    "\n",
    "            p {\n",
    "                font-size: 16px;\n",
    "            }\n",
    "\n",
    "            .highlight-container, .highlight {\n",
    "                position: relative;\n",
    "                border-radius: 10% 10% 10% 10%;\n",
    "            }\n",
    "\n",
    "            .highlight-container {\n",
    "                display: inline-block;\n",
    "            }\n",
    "\n",
    "            .highlight-container:before {\n",
    "                content: \" \";\n",
    "                display: block;\n",
    "                height: 90%;\n",
    "                width: 100%;\n",
    "                margin-left: -3px;\n",
    "                margin-right: -3px;\n",
    "                position: absolute;\n",
    "                top: -1px;\n",
    "                left: -1px;\n",
    "                padding: 10px 3px 3px 10px;\n",
    "            }\n",
    "\n",
    "        </style>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    html_heatmap = style\n",
    "    for i, j in zip(explanations, predicted_labels):\n",
    "        name = CLASS_NAMES[j]\n",
    "        div = _create_div(i, name)\n",
    "        html_heatmap += div\n",
    "    return html_heatmap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generate and visualize explanations using baseline methods: Gradient Norm and IntegratedGradients"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def explain_gradient_norm(model, input, target, model_name, tokenizer):\n",
    "    token_ids = tokenizer([input], return_tensors='tf')[\"input_ids\"]\n",
    "    embeddings = getattr(model, model_name).get_input_embeddings()(input_ids=token_ids)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(embeddings)\n",
    "        logits = model(None, inputs_embeds=embeddings).logits\n",
    "        logits_for_label = tf.gather(logits, axis=1, indices=target)\n",
    "    grads = tape.gradient(logits_for_label, embeddings)\n",
    "    grad_norm = tf.linalg.norm(grads, axis=-1)\n",
    "    return qn.TokenSalience(\n",
    "        tokenizer.convert_ids_to_tokens(token_ids[0]), grad_norm.numpy()[0]\n",
    "    )\n",
    "\n",
    "\n",
    "def explain_gradient_norm_batch(model: tf.keras.Model, inputs, targets, model_name, tokenizer):\n",
    "    return [\n",
    "        explain_gradient_norm(model, x, y, model_name, tokenizer)\n",
    "        for x, y in zip(inputs, targets)\n",
    "    ]\n",
    "\n",
    "\n",
    "explain_gradient_norm_func = partial(explain_gradient_norm_batch, model_name=\"distilbert\", tokenizer=tokenizer)\n",
    "a_batch_grad_norm = explain_gradient_norm_func(model, x_batch, y_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n        <style>\n\n            .container {\n                line-height: 1.4;\n                text-align: center;\n                margin: 10px 10px 10px 10px;\n                color: black;\n                background: white;\n            }\n\n            p {\n                font-size: 16px;\n            }\n\n            .highlight-container, .highlight {\n                position: relative;\n                border-radius: 10% 10% 10% 10%;\n            }\n\n            .highlight-container {\n                display: inline-block;\n            }\n\n            .highlight-container:before {\n                content: \" \";\n                display: block;\n                height: 90%;\n                width: 100%;\n                margin-left: -3px;\n                margin-right: -3px;\n                position: absolute;\n                top: -1px;\n                left: -1px;\n                padding: 10px 3px 3px 10px;\n            }\n\n        </style>\n        \n        <div class=\"container\">\n            <p>\n                Predicted: negative <br>\n                \n        <span class=\"highlight-container\" style=\"background:rgb(255,0.0,0.0);\">\n            <span class=\"highlight\"> [CLS] </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,129.56116899847984,129.56116899847984);\">\n            <span class=\"highlight\"> uneasy </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,158.3971832692623,158.3971832692623);\">\n            <span class=\"highlight\"> mis </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,90.56183248758316,90.56183248758316);\">\n            <span class=\"highlight\"> ##hma </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,180.68244025111198,180.68244025111198);\">\n            <span class=\"highlight\"> ##sh </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,197.8882285952568,197.8882285952568);\">\n            <span class=\"highlight\"> of </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,200.3621580451727,200.3621580451727);\">\n            <span class=\"highlight\"> styles </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,223.40868707746267,223.40868707746267);\">\n            <span class=\"highlight\"> and </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,215.4944432526827,215.4944432526827);\">\n            <span class=\"highlight\"> genres </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,224.0026332065463,224.0026332065463);\">\n            <span class=\"highlight\"> . </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,209.945460408926,209.945460408926);\">\n            <span class=\"highlight\"> [SEP] </span>\n        </span>\n         \n            </p>\n        </div>\n        \n        <div class=\"container\">\n            <p>\n                Predicted: negative <br>\n                \n        <span class=\"highlight-container\" style=\"background:rgb(255,11.84163898229599,11.84163898229599);\">\n            <span class=\"highlight\"> [CLS] </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,230.1662653684616,230.1662653684616);\">\n            <span class=\"highlight\"> this </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,205.22528149187565,205.22528149187565);\">\n            <span class=\"highlight\"> film </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,238.8402233272791,238.8402233272791);\">\n            <span class=\"highlight\"> ' </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,237.27960146963596,237.27960146963596);\">\n            <span class=\"highlight\"> s </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,192.9602312296629,192.9602312296629);\">\n            <span class=\"highlight\"> relationship </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,223.68307415395975,223.68307415395975);\">\n            <span class=\"highlight\"> to </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,220.51579400897026,220.51579400897026);\">\n            <span class=\"highlight\"> actual </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,206.5969280898571,206.5969280898571);\">\n            <span class=\"highlight\"> tension </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,225.80527927726507,225.80527927726507);\">\n            <span class=\"highlight\"> is </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,230.87941870093346,230.87941870093346);\">\n            <span class=\"highlight\"> the </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,208.82293984293938,208.82293984293938);\">\n            <span class=\"highlight\"> same </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,207.88844838738441,207.88844838738441);\">\n            <span class=\"highlight\"> as </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,196.98313996195793,196.98313996195793);\">\n            <span class=\"highlight\"> what </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,220.40243849158287,220.40243849158287);\">\n            <span class=\"highlight\"> christmas </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,228.69906719774008,228.69906719774008);\">\n            <span class=\"highlight\"> - </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,220.20126968622208,220.20126968622208);\">\n            <span class=\"highlight\"> tree </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,194.0909593552351,194.0909593552351);\">\n            <span class=\"highlight\"> flock </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,231.5570268407464,231.5570268407464);\">\n            <span class=\"highlight\"> ##ing </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,226.01141061633825,226.01141061633825);\">\n            <span class=\"highlight\"> in </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,231.08343925327063,231.08343925327063);\">\n            <span class=\"highlight\"> a </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,219.8253520578146,219.8253520578146);\">\n            <span class=\"highlight\"> spray </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,228.152878805995,228.152878805995);\">\n            <span class=\"highlight\"> can </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,198.0972895771265,198.0972895771265);\">\n            <span class=\"highlight\"> is </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,211.74662075936794,211.74662075936794);\">\n            <span class=\"highlight\"> to </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,206.079338863492,206.079338863492);\">\n            <span class=\"highlight\"> actual </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,211.13237231969833,211.13237231969833);\">\n            <span class=\"highlight\"> snow </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,169.59657311439514,169.59657311439514);\">\n            <span class=\"highlight\"> : </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,179.0295061469078,179.0295061469078);\">\n            <span class=\"highlight\"> a </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,0.0,0.0);\">\n            <span class=\"highlight\"> poor </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,144.10809561610222,144.10809561610222);\">\n            <span class=\"highlight\"> - </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,167.349753677845,167.349753677845);\">\n            <span class=\"highlight\"> - </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,147.2029459476471,147.2029459476471);\">\n            <span class=\"highlight\"> if </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,144.8795986175537,144.8795986175537);\">\n            <span class=\"highlight\"> durable </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,207.51552119851112,207.51552119851112);\">\n            <span class=\"highlight\"> - </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,166.35335594415665,166.35335594415665);\">\n            <span class=\"highlight\"> - </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,61.489850878715515,61.489850878715515);\">\n            <span class=\"highlight\"> imitation </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,217.36173525452614,217.36173525452614);\">\n            <span class=\"highlight\"> . </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,176.50357648730278,176.50357648730278);\">\n            <span class=\"highlight\"> [SEP] </span>\n        </span>\n         \n            </p>\n        </div>\n        \n        <div class=\"container\">\n            <p>\n                Predicted: positive <br>\n                \n        <span class=\"highlight-container\" style=\"background:rgb(255,0.0,0.0);\">\n            <span class=\"highlight\"> [CLS] </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,206.72122702002525,206.72122702002525);\">\n            <span class=\"highlight\"> by </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,216.8461599200964,216.8461599200964);\">\n            <span class=\"highlight\"> the </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,195.67079678177834,195.67079678177834);\">\n            <span class=\"highlight\"> end </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,161.43491506576538,161.43491506576538);\">\n            <span class=\"highlight\"> of </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,140.6758537888527,140.6758537888527);\">\n            <span class=\"highlight\"> no </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,140.74820950627327,140.74820950627327);\">\n            <span class=\"highlight\"> such </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,146.13303735852242,146.13303735852242);\">\n            <span class=\"highlight\"> thing </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,156.05603769421577,156.05603769421577);\">\n            <span class=\"highlight\"> the </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,130.82698747515678,130.82698747515678);\">\n            <span class=\"highlight\"> audience </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,193.87946270406246,193.87946270406246);\">\n            <span class=\"highlight\"> , </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,182.39478036761284,182.39478036761284);\">\n            <span class=\"highlight\"> like </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,169.16728734970093,169.16728734970093);\">\n            <span class=\"highlight\"> beatrice </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,186.37599393725395,186.37599393725395);\">\n            <span class=\"highlight\"> , </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,168.15344855189323,168.15344855189323);\">\n            <span class=\"highlight\"> has </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,90.3153321146965,90.3153321146965);\">\n            <span class=\"highlight\"> a </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,3.9623209834098816,3.9623209834098816);\">\n            <span class=\"highlight\"> watch </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,132.94072285294533,132.94072285294533);\">\n            <span class=\"highlight\"> ##ful </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,70.44127374887466,70.44127374887466);\">\n            <span class=\"highlight\"> affection </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,180.31708985567093,180.31708985567093);\">\n            <span class=\"highlight\"> for </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,194.43554006516933,194.43554006516933);\">\n            <span class=\"highlight\"> the </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,122.29693919420242,122.29693919420242);\">\n            <span class=\"highlight\"> monster </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,207.00986713171005,207.00986713171005);\">\n            <span class=\"highlight\"> . </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,165.7252648472786,165.7252648472786);\">\n            <span class=\"highlight\"> [SEP] </span>\n        </span>\n         \n            </p>\n        </div>\n        "
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = create_textual_heatmap(a_batch_grad_norm[:3], y_batch[:3])\n",
    "HTML(html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def get_interpolated_inputs(\n",
    "        baseline: np.ndarray, target: np.ndarray, num_steps=10\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Gets num_step linearly interpolated inputs from baseline to target.\"\"\"\n",
    "    if num_steps <= 0:\n",
    "        return np.array([])\n",
    "    if num_steps == 1:\n",
    "        return np.array([baseline, target])\n",
    "\n",
    "    delta = target - baseline  # <float32>[num_tokens, emb_size]\n",
    "    # Creates scale values array of shape [num_steps, num_tokens, emb_dim],\n",
    "    # where the values in scales[i] are the ith step from np.linspace.\n",
    "    # <float32>[num_steps, 1, 1]\n",
    "    scales = np.linspace(0, 1, num_steps + 1, dtype=np.float32)[\n",
    "             :, np.newaxis, np.newaxis\n",
    "             ]\n",
    "    shape = (num_steps + 1,) + delta.shape\n",
    "    # <float32>[num_steps, num_tokens, emb_size]\n",
    "    deltas = scales * np.broadcast_to(delta, shape)\n",
    "    interpolated_inputs = baseline + deltas\n",
    "    return interpolated_inputs  # <float32>[num_steps, num_tokens, emb_size]\n",
    "\n",
    "\n",
    "def estimate_integral(path_gradients: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Estimates the integral of the path_gradients using trapezoid rule.\"\"\"\n",
    "    path_gradients = (path_gradients[:-1] + path_gradients[1:]) / 2\n",
    "    return tf.reduce_mean(path_gradients, axis=(0, 2))\n",
    "\n",
    "\n",
    "def explain_int_grad(tokenizer, model: tf.keras.Model, input, target, model_name):\n",
    "    token_ids = tokenizer([input], return_tensors='tf')[\"input_ids\"]\n",
    "    embeddings = getattr(model, model_name).get_input_embeddings()(input_ids=token_ids)[\n",
    "        0\n",
    "    ]\n",
    "    baseline = np.zeros_like(embeddings)\n",
    "    interpolated_embeddings = get_interpolated_inputs(baseline, embeddings)\n",
    "    interpolated_embeddings = tf.convert_to_tensor(interpolated_embeddings)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_embeddings)\n",
    "        logits = model(None, inputs_embeds=interpolated_embeddings).logits\n",
    "        logits_for_label = tf.gather(logits, axis=1, indices=target)\n",
    "    grads = tape.gradient(logits_for_label, interpolated_embeddings)\n",
    "    int_grad = estimate_integral(grads)\n",
    "    stddev = tf.math.reduce_std(int_grad)\n",
    "    normalized_int_grad = tf.abs(int_grad / stddev)\n",
    "    return qn.TokenSalience(\n",
    "        tokenizer.convert_ids_to_tokens(token_ids[0]), normalized_int_grad.numpy()\n",
    "    )\n",
    "\n",
    "\n",
    "def explain_int_grad_batch(model, inputs, targets, tokenizer, model_name):\n",
    "    return [\n",
    "        explain_int_grad(\n",
    "            tokenizer=tokenizer, model=model, input=x, target=y, model_name=model_name\n",
    "        ) for x, y in zip(inputs, targets)\n",
    "    ]\n",
    "\n",
    "\n",
    "explain_int_grad_func = partial(explain_int_grad_batch, model_name=\"distilbert\", tokenizer=tokenizer)\n",
    "\n",
    "a_batch_int_grad = explain_int_grad_func(model, x_batch, y_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n        <style>\n\n            .container {\n                line-height: 1.4;\n                text-align: center;\n                margin: 10px 10px 10px 10px;\n                color: black;\n                background: white;\n            }\n\n            p {\n                font-size: 16px;\n            }\n\n            .highlight-container, .highlight {\n                position: relative;\n                border-radius: 10% 10% 10% 10%;\n            }\n\n            .highlight-container {\n                display: inline-block;\n            }\n\n            .highlight-container:before {\n                content: \" \";\n                display: block;\n                height: 90%;\n                width: 100%;\n                margin-left: -3px;\n                margin-right: -3px;\n                position: absolute;\n                top: -1px;\n                left: -1px;\n                padding: 10px 3px 3px 10px;\n            }\n\n        </style>\n        \n        <div class=\"container\">\n            <p>\n                Predicted: negative <br>\n                \n        <span class=\"highlight-container\" style=\"background:rgb(255,178.49999696016312,178.49999696016312);\">\n            <span class=\"highlight\"> [CLS] </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,0.0,0.0);\">\n            <span class=\"highlight\"> uneasy </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,203.99999924004078,203.99999924004078);\">\n            <span class=\"highlight\"> mis </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,203.99999924004078,203.99999924004078);\">\n            <span class=\"highlight\"> ##hma </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,50.99999696016312,50.99999696016312);\">\n            <span class=\"highlight\"> ##sh </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,152.99999848008156,152.99999848008156);\">\n            <span class=\"highlight\"> of </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,50.99999696016312,50.99999696016312);\">\n            <span class=\"highlight\"> styles </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,0.0,0.0);\">\n            <span class=\"highlight\"> and </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,229.4999996200204,229.4999996200204);\">\n            <span class=\"highlight\"> genres </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,203.99999924004078,203.99999924004078);\">\n            <span class=\"highlight\"> . </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,127.5,127.5);\">\n            <span class=\"highlight\"> [SEP] </span>\n        </span>\n         \n            </p>\n        </div>\n        \n        <div class=\"container\">\n            <p>\n                Predicted: negative <br>\n                \n        <span class=\"highlight-container\" style=\"background:rgb(255,255.0,255.0);\">\n            <span class=\"highlight\"> [CLS] </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,229.49999772012234,229.49999772012234);\">\n            <span class=\"highlight\"> this </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,203.99999544024467,203.99999544024467);\">\n            <span class=\"highlight\"> film </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,159.375,159.375);\">\n            <span class=\"highlight\"> ' </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,250.2187498100102,250.2187498100102);\">\n            <span class=\"highlight\"> s </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,203.99999544024467,203.99999544024467);\">\n            <span class=\"highlight\"> relationship </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,242.24999886006117,242.24999886006117);\">\n            <span class=\"highlight\"> to </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,159.375,159.375);\">\n            <span class=\"highlight\"> actual </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,255.0,255.0);\">\n            <span class=\"highlight\"> tension </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,203.99999544024467,203.99999544024467);\">\n            <span class=\"highlight\"> is </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,234.28124886006117,234.28124886006117);\">\n            <span class=\"highlight\"> the </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,216.74999848008156,216.74999848008156);\">\n            <span class=\"highlight\"> same </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,203.99999544024467,203.99999544024467);\">\n            <span class=\"highlight\"> as </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,235.87499924004078,235.87499924004078);\">\n            <span class=\"highlight\"> what </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,255.0,255.0);\">\n            <span class=\"highlight\"> christmas </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,223.125,223.125);\">\n            <span class=\"highlight\"> - </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,255.0,255.0);\">\n            <span class=\"highlight\"> tree </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,178.49999696016312,178.49999696016312);\">\n            <span class=\"highlight\"> flock </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,223.125,223.125);\">\n            <span class=\"highlight\"> ##ing </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,248.62499943003058,248.62499943003058);\">\n            <span class=\"highlight\"> in </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,242.24999886006117,242.24999886006117);\">\n            <span class=\"highlight\"> a </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,203.99999544024467,203.99999544024467);\">\n            <span class=\"highlight\"> spray </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,248.62499943003058,248.62499943003058);\">\n            <span class=\"highlight\"> can </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,207.1875,207.1875);\">\n            <span class=\"highlight\"> is </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,175.3124924004078,175.3124924004078);\">\n            <span class=\"highlight\"> to </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,229.49999772012234,229.49999772012234);\">\n            <span class=\"highlight\"> actual </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,229.49999772012234,229.49999772012234);\">\n            <span class=\"highlight\"> snow </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,178.49999696016312,178.49999696016312);\">\n            <span class=\"highlight\"> : </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,255.0,255.0);\">\n            <span class=\"highlight\"> a </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,0.0,0.0);\">\n            <span class=\"highlight\"> poor </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,152.99999088048935,152.99999088048935);\">\n            <span class=\"highlight\"> - </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,229.49999772012234,229.49999772012234);\">\n            <span class=\"highlight\"> - </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,89.24999088048935,89.24999088048935);\">\n            <span class=\"highlight\"> if </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,50.9999817609787,50.9999817609787);\">\n            <span class=\"highlight\"> durable </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,235.87499924004078,235.87499924004078);\">\n            <span class=\"highlight\"> - </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,203.99999544024467,203.99999544024467);\">\n            <span class=\"highlight\"> - </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,50.9999817609787,50.9999817609787);\">\n            <span class=\"highlight\"> imitation </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,197.62499772012234,197.62499772012234);\">\n            <span class=\"highlight\"> . </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,152.99999088048935,152.99999088048935);\">\n            <span class=\"highlight\"> [SEP] </span>\n        </span>\n         \n            </p>\n        </div>\n        \n        <div class=\"container\">\n            <p>\n                Predicted: positive <br>\n                \n        <span class=\"highlight-container\" style=\"background:rgb(255,245.1923082768917,245.1923082768917);\">\n            <span class=\"highlight\"> [CLS] </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,205.96153758466244,205.96153758466244);\">\n            <span class=\"highlight\"> by </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,210.8653872460127,210.8653872460127);\">\n            <span class=\"highlight\"> the </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,215.76923310756683,215.76923310756683);\">\n            <span class=\"highlight\"> end </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,245.1923082768917,245.1923082768917);\">\n            <span class=\"highlight\"> of </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,225.57692103087902,225.57692103087902);\">\n            <span class=\"highlight\"> no </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,196.15384206175804,196.15384206175804);\">\n            <span class=\"highlight\"> such </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,147.11538344621658,147.11538344621658);\">\n            <span class=\"highlight\"> thing </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,245.1923082768917,245.1923082768917);\">\n            <span class=\"highlight\"> the </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,213.3173044770956,213.3173044770956);\">\n            <span class=\"highlight\"> audience </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,250.09615413844585,250.09615413844585);\">\n            <span class=\"highlight\"> , </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,235.38461655378342,235.38461655378342);\">\n            <span class=\"highlight\"> like </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,235.38461655378342,235.38461655378342);\">\n            <span class=\"highlight\"> beatrice </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,245.1923082768917,245.1923082768917);\">\n            <span class=\"highlight\"> , </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,215.76923310756683,215.76923310756683);\">\n            <span class=\"highlight\"> has </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,215.76923310756683,215.76923310756683);\">\n            <span class=\"highlight\"> a </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,0.0,0.0);\">\n            <span class=\"highlight\"> watch </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,166.73077449202538,166.73077449202538);\">\n            <span class=\"highlight\"> ##ful </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,166.73077449202538,166.73077449202538);\">\n            <span class=\"highlight\"> affection </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,245.1923082768917,245.1923082768917);\">\n            <span class=\"highlight\"> for </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,215.76923310756683,215.76923310756683);\">\n            <span class=\"highlight\"> the </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,255.0,255.0);\">\n            <span class=\"highlight\"> monster </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,235.38461655378342,235.38461655378342);\">\n            <span class=\"highlight\"> . </span>\n        </span>\n         \n        <span class=\"highlight-container\" style=\"background:rgb(255,166.73077449202538,166.73077449202538);\">\n            <span class=\"highlight\"> [SEP] </span>\n        </span>\n         \n            </p>\n        </div>\n        "
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = create_textual_heatmap(a_batch_int_grad[:3], y_batch[:3])\n",
    "HTML(html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Now we compute [Sensitivity](https://arxiv.org/abs/2005.00631) metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# This is only a workaround to account for hardcoded attribute access in lib\n",
    "class ModelTuple(NamedTuple):\n",
    "    model: Any\n",
    "    tokenizer: Any\n",
    "\n",
    "\n",
    "model_stub = ModelTuple(model, tokenizer)\n",
    "model_stub.model.bert = model.distilbert\n",
    "model_stub.model.bert.embeddings.word_embeddings = model.distilbert.embeddings.weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Average Sensitivity captures the average change in explanations under slight perturbation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "Collecting perturbations:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b13f397b6cb74ff5bc1db171a2b84492"
      },
      "application/json": {
       "n": 0,
       "total": 10,
       "elapsed": 0.03360104560852051,
       "ncols": null,
       "nrows": null,
       "prefix": "Collecting perturbations",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Collecting explanations:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1b11333d3e243849d4a377c8f3023e4"
      },
      "application/json": {
       "n": 0,
       "total": 8,
       "elapsed": 0.01890110969543457,
       "ncols": null,
       "nrows": null,
       "prefix": "Collecting explanations",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Collecting perturbations:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e68b66f5cf34f5b9b718ffbce5bc940"
      },
      "application/json": {
       "n": 0,
       "total": 10,
       "elapsed": 0.023625850677490234,
       "ncols": null,
       "nrows": null,
       "prefix": "Collecting perturbations",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Collecting explanations:   0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8489ab0f2e0b4b34a5e82e5cb822a334"
      },
      "application/json": {
       "n": 0,
       "total": 9,
       "elapsed": 0.016475915908813477,
       "ncols": null,
       "nrows": null,
       "prefix": "Collecting explanations",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_sensitivity = qn.AvgSensitivity()\n",
    "\n",
    "avg_sensitivity_grad_norm = avg_sensitivity(\n",
    "    model=model_stub,\n",
    "    x_batch=x_batch,\n",
    "    y_batch=y_batch,\n",
    "    perturb_func=qn.change_spelling,\n",
    "    explain_func=explain_gradient_norm_func,\n",
    ").mean()\n",
    "\n",
    "avg_sensitivity_int_grad = avg_sensitivity(\n",
    "    model=model_stub,\n",
    "    x_batch=x_batch,\n",
    "    y_batch=y_batch,\n",
    "    perturb_func=qn.change_spelling,\n",
    "    explain_func=explain_int_grad_func\n",
    ").mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Maximum Sensitivity captures the maximal change in explanations under slight perturbation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "Collecting perturbations:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d4ef8aaad08430685cf9aa4794e9999"
      },
      "application/json": {
       "n": 0,
       "total": 10,
       "elapsed": 0.019996166229248047,
       "ncols": null,
       "nrows": null,
       "prefix": "Collecting perturbations",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Collecting explanations:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f87773bf0b146d68b04b02055e44606"
      },
      "application/json": {
       "n": 0,
       "total": 7,
       "elapsed": 0.027589082717895508,
       "ncols": null,
       "nrows": null,
       "prefix": "Collecting explanations",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Collecting perturbations:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cabb1848c0bb47e494648e2df018e071"
      },
      "application/json": {
       "n": 0,
       "total": 10,
       "elapsed": 0.020277023315429688,
       "ncols": null,
       "nrows": null,
       "prefix": "Collecting perturbations",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Collecting explanations:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d48e0d1cb41f4d39899f081e0b949964"
      },
      "application/json": {
       "n": 0,
       "total": 8,
       "elapsed": 0.017493009567260742,
       "ncols": null,
       "nrows": null,
       "prefix": "Collecting explanations",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_sensitivity = qn.MaxSensitivity()\n",
    "\n",
    "max_sensitivity_grad_norm = max_sensitivity(\n",
    "    model=model_stub,\n",
    "    x_batch=x_batch,\n",
    "    y_batch=y_batch,\n",
    "    perturb_func=qn.change_spelling,\n",
    "    explain_func=explain_gradient_norm_func,\n",
    ").mean()\n",
    "\n",
    "max_sensitivity_int_grad = max_sensitivity(\n",
    "    model=model_stub,\n",
    "    x_batch=x_batch,\n",
    "    y_batch=y_batch,\n",
    "    perturb_func=qn.change_spelling,\n",
    "    explain_func=explain_int_grad_func\n",
    ").mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display results in tabular form"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "                     GradNorm   IntGrad\nAverage Sensitivity  0.192660  0.607145\nMax Sensetivity      0.290634  0.756526",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GradNorm</th>\n      <th>IntGrad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Average Sensitivity</th>\n      <td>0.192660</td>\n      <td>0.607145</td>\n    </tr>\n    <tr>\n      <th>Max Sensetivity</th>\n      <td>0.290634</td>\n      <td>0.756526</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = np.asarray([\n",
    "    [\n",
    "        avg_sensitivity_grad_norm,\n",
    "        avg_sensitivity_int_grad\n",
    "    ],\n",
    "    [\n",
    "        max_sensitivity_grad_norm,\n",
    "        max_sensitivity_int_grad\n",
    "    ]\n",
    "])\n",
    "pd.DataFrame(\n",
    "    all_results,\n",
    "    columns=['GradNorm', 'IntGrad'],\n",
    "    index=['Average Sensitivity', 'Max Sensitivity']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
