{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This notebook shows the functionality of the RobustnessTest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#import xaiquantificationtoolbox\n",
    "\n",
    "# Imports for now ...\n",
    "from ...xai_quantification_toolbox.measures.robustness_test import *\n",
    "from ...xai_quantification_toolbox.loaders.model_interface import *\n",
    "from ...xai_quantification_toolbox.quantifier.base import *\n",
    "from ....NoiseGrad.src.models import ResNet18\n",
    "import h5py\n",
    "\n",
    "# Load trained pytorch model.\n",
    "model = ResNet18()\n",
    "model.load_state_dict(torch.load(\"PATH_TO_LEARNED_PARAMETERS\"))\n",
    "model.eval()\n",
    "model = ModelInterface()\n",
    "\n",
    "# Load data, targets and attributions.\n",
    "inputs = None\n",
    "targets = None\n",
    "attributions = None\n",
    "\n",
    "# Option 1. One can run the RobustnessTest very simply and just return the scores.\n",
    "scores = RobustnessTest(**{\n",
    "    \"similarity_function\": lipschitz_constant,\n",
    "    \"perturbation_function\": gaussian_blur,\n",
    "})(model=model, inputs=inputs, targets=targets, attributions=attributions)\n",
    "\n",
    "# Option 2. One can run the RobustnessTest using the Quantifier to specify more meta-configs and therefore enjoy more functionality.\n",
    "\n",
    "# Specify the tests.\n",
    "tests = [RobustnessTest(**{\n",
    "    \"similarity_function\": similarity_function,\n",
    "    \"perturbation_function\": gaussian_blur,\n",
    "}) for similarity_function in [lipschitz_constant, distance_euclidean, cosine]]\n",
    "\n",
    "# Init the quantifier object.\n",
    "quantifier = Quantifier(measures=tests, io_object=h5py.File(...), checkpoints=..)\n",
    "\n",
    "# Score the tests.\n",
    "scores = quantifier.score(model=model, inputs=inputs, targets=targets, attributions=attributions)\n",
    "\n",
    "if __class__.__name__ == \"RobustnessTest\":\n",
    "    pass \"do this\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}